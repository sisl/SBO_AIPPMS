struct MonteCarloTreeSearch<: Policy
    rng
    ð’« # problem
    N # visit counts
    Q # action value estimates
    m # number of simulations
    d # depth
    c # exploration constant
    U # value function estimate
end

function (Ï€::MonteCarloTreeSearch)(s)
    for k in 1:Ï€.m
        simulate!(Ï€, s)
    end
    if actions(Ï€.ð’«, s) == ()
        return :wait
    else
        return argmax(a->Ï€.Q[(s,a)], actions(Ï€.ð’«, s))
    end
end

function POMDPs.action(Ï€::MonteCarloTreeSearch, s)
    return Ï€(s)
end

function simulate!(Ï€::MonteCarloTreeSearch, s, d=Ï€.d)
    if d â‰¤ 0
        return Ï€.U(s)
    end
    ð’«, N, Q, c = Ï€.ð’«, Ï€.N, Ï€.Q, Ï€.c
    ð’œ, T, Î³ = actions(ð’«, s), ((s,a)->POMDPs.transition(ð’«, s, a, Ï€.rng)), ð’«.discount
    R = (s,a,sp)->POMDPs.reward(ð’«, s, a, sp)

    if ð’œ == MultimodalIPPAction[]
        return 0
    end

    if !haskey(N, (s, first(ð’œ)))
        for a in ð’œ
            N[(s,a)] = 0
            Q[(s,a)] = 0.0
        end
        return Ï€.U(s)
    end
    a = explore(Ï€, s)
    sâ€²= T(s,a)
    r = R(s,a,sâ€²)
    q = r + Î³*simulate!(Ï€, sâ€², d-1)
    N[(s,a)] += 1
    Q[(s,a)] += (q-Q[(s,a)])/N[(s,a)]
    return q
end

bonus(Nsa, Ns) = Nsa == 0 ? Inf : sqrt(log(Ns)/Nsa)
function explore(Ï€::MonteCarloTreeSearch, s)
    ð’œ, N, Q, c = actions(Ï€.ð’«, s), Ï€.N, Ï€.Q, Ï€.c
    Ns = sum(N[(s,a)] for a in ð’œ)
    return argmax(a->Q[(s,a)] + c*bonus(N[(s,a)], Ns), ð’œ)
end

# TODO: Define rollout policy

function randstep(ð’«, s, a, rng)
    T = ((s,a)->POMDPs.transition(ð’«, s, a, rng))
    R = (s,a,sp)->POMDPs.reward(ð’«, s, a, sp)
    sp = T(s,a)
    return (sp, R(s,a,sp))
end

function RandomRollout(rng, ð’«, s, d)
    ret = 0.0
    for t in 1:d
        ð’œ = actions(ð’«, s)
        if ð’œ == MultimodalIPPAction[]
            return 0
        else
            a = rand(rng, ð’œ) #Ï€(s)
        end
        s, r = randstep(ð’«, s, a, rng)
        ret += ð’«.discount^(t-1) * r
    end
    return ret
end

function SeekTarget(rng, ð’«, s, target=ð’«.goal_pos)
    if rand(rng) > 0.8
        ð’œ = actions(ð’«, s)
        if ð’œ == ()
            return Nothing
        end
        a = rand(rng, ð’œ)
        return a
    else
        ð’œ = actions(ð’«, s)
        if ð’œ == ()
            return Nothing
        end

        if (target[1] > s.pos[1]) & (target[2] > s.pos[2])
            if inbounds(ð’«, s.pos + ð’«.step_size*dir[:NE])
                return :NE
            else
                return rand(rng, ð’œ)
            end
        elseif (target[1] > s.pos[1])
            if inbounds(ð’«, s.pos + ð’«.step_size*dir[:right])
                return :right
            else
                return rand(rng, ð’œ)
            end
        elseif target[2] > s.pos[2]
            if inbounds(ð’«, s.pos + ð’«.step_size*dir[:up])
                return :up
            else
                return rand(rng, ð’œ)
            end
        else
            if inbounds(ð’«, s.pos + ð’«.step_size*dir[:down])
                return :down
            else
                return rand(rng, ð’œ)
            end
        end
    end
end

function TargetRollout(rng, ð’«, s, d)
    ret = 0.0
    ð’œ = actions(ð’«, s)
    for t in 1:d
        # if t == d
        #     println("final state: ", s.pos)
        # end
        a = SeekTarget(rng, ð’«, s) #Ï€(s)
        if a == Nothing
            r = -10000.0
            ret += ð’«.discount^(t-1) * r
        else
            s, r = randstep(ð’«, s, a, rng)
            ret += ð’«.discount^(t-1) * r
        end
    end
    return ret
end

# U(s)=RandomRollout(pomdp, s, Ï€.d)
# Ï€_rand=MonteCarloTreeSearch(pomdp, Dict(), Dict(), 30, 20, 1.0, U)

# U(s)=TargetRollout(pomdp, s, Ï€.d)
# Ï€_target=MonteCarloTreeSearch(pomdp, Dict(), Dict(), 30, 20, 1.0, U)


function custom_stepthrough(ð’«, Ï€, s; max_steps=500, rng=MersenneTwister(3))
    s_init = deepcopy(s)
    state_hist = []
    action_hist = []
    for i in 1:max_steps
        println(i)
        state_hist = vcat(state_hist, [[s.pos[1], s.pos[2]]])
        a = Ï€(s)
        println(a)
        action_hist = vcat(action_hist, a)
        s = POMDPs.transition(ð’«, s, a)
    end

#    state_hist2 = []
#    action_hist2 = []
#    s = s_init
#    for i in 1:max_steps
#        println(i)
#        state_hist2 = vcat(state_hist2, [[s.pos[1], s.pos[2]]])
#        a = Ï€(s)
#        println(a)
#        action_hist2 = vcat(action_hist2, a)
#        s = POMDPs.transition(ð’«, s, a).val
#    end

#    return (state_hist, action_hist, state_hist2, action_hist2)
     return (state_hist, action_hist)
end



# include("MCTS.jl")
# Ï€=MonteCarloTreeSearch(pomdp, Dict(), Dict(), 30, 20, 1.0, (x->0.0))
# state_hist, action_hist =stepthrough(pomdp, Ï€, SSTDistribution(GWPos(1,1), 0, f_prior))
# fourth_policy=MonteCarloTreeSearch(pomdp, Dict(), Dict(), 500, 300, 1.0, (x->0.0))
# state_hist, action_hist =stepthrough(pomdp, fourth_policy, SSTDistribution(GWPos(1,1), 0, f_prior))
